diff --git a/docs/features.txt b/docs/features.txt
index 859adae..d649341 100644
--- a/docs/features.txt
+++ b/docs/features.txt
@@ -307,7 +307,7 @@ Khronos, ARB, and OES extensions that are not part of any OpenGL or OpenGL ES ve
   GL_ARB_sample_locations                               DONE (freedreno/a6xx, nvc0, zink)
   GL_ARB_seamless_cubemap_per_texture                   DONE (etnaviv/SEAMLESS_CUBE_MAP, freedreno, nvc0, r600, radeonsi, softpipe, virgl, zink, asahi, iris, crocus)
   GL_ARB_shader_ballot                                  DONE (nvc0, radeonsi, zink, iris, crocus/gen8, d3d12, asahi)
-  GL_ARB_shader_clock                                   DONE (nv50, nvc0, r600, radeonsi, llvmpipe, virgl, zink, iris, crocus/gen7+)
+  GL_ARB_shader_clock                                   DONE (freedreno/a6xx, nv50, nvc0, r600, radeonsi, llvmpipe, virgl, zink, iris, crocus/gen7+)
   GL_ARB_shader_stencil_export                          DONE (r600, radeonsi, softpipe, llvmpipe, virgl, panfrost, zink, asahi, iris/gen9+)
   GL_ARB_shader_viewport_layer_array                    DONE (freedreno/a6xx, nvc0, radeonsi, zink, iris, crocus/gen6+, asahi)
   GL_ARB_shading_language_include                       DONE
@@ -544,7 +544,7 @@ Khronos extensions that are not part of any Vulkan version:
   VK_KHR_ray_tracing_maintenance1                       DONE (anv/gfx12.5+, radv/gfx10.3+)
   VK_KHR_ray_tracing_pipeline                           DONE (anv/gfx12.5+, lvp, radv/gfx10.3+)
   VK_KHR_ray_tracing_position_fetch                     DONE (anv, radv/gfx10.3+)
-  VK_KHR_shader_clock                                   DONE (anv, hasvk, lvp, nvk, radv, vn)
+  VK_KHR_shader_clock                                   DONE (anv, hasvk, lvp, nvk, radv, tu, vn)
   VK_KHR_shader_expect_assume                           DONE (anv, dzn, hasvk, lvp, nvk, panvk, pvr, radv, tu, v3dv, vn)
   VK_KHR_shader_float_controls2                         DONE (anv, nvk, radv, tu)
   VK_KHR_shader_maximal_reconvergence                   DONE (anv, lvp, nvk, radv)
diff --git a/include/drm-uapi/msm_drm.h b/include/drm-uapi/msm_drm.h
index b916aab..2342cb9 100644
--- a/include/drm-uapi/msm_drm.h
+++ b/include/drm-uapi/msm_drm.h
@@ -90,6 +90,7 @@ struct drm_msm_timespec {
 #define MSM_PARAM_RAYTRACING 0x11 /* RO */
 #define MSM_PARAM_UBWC_SWIZZLE 0x12 /* RO */
 #define MSM_PARAM_MACROTILE_MODE 0x13 /* RO */
+#define MSM_PARAM_UCHE_TRAP_BASE 0x14 /* RO */
 
 /* For backwards compat.  The original support for preemption was based on
  * a single ring per priority level so # of priority levels equals the #
diff --git a/src/freedreno/drm/freedreno_drmif.h b/src/freedreno/drm/freedreno_drmif.h
index 4cc3391..cfc34e3 100644
--- a/src/freedreno/drm/freedreno_drmif.h
+++ b/src/freedreno/drm/freedreno_drmif.h
@@ -47,6 +47,7 @@ enum fd_param_id {
    FD_SUSPEND_COUNT, /* # of times the GPU has suspended, and potentially lost state */
    FD_SYSPROF,       /* Settable (for CAP_SYS_ADMIN) param for system profiling */
    FD_VA_SIZE,       /* GPU virtual address size */
+   FD_UCHE_TRAP_BASE
 };
 
 /**
diff --git a/src/freedreno/drm/msm/msm_pipe.c b/src/freedreno/drm/msm/msm_pipe.c
index 6e51900..c80f1b3 100644
--- a/src/freedreno/drm/msm/msm_pipe.c
+++ b/src/freedreno/drm/msm/msm_pipe.c
@@ -84,6 +84,8 @@ msm_pipe_get_param(struct fd_pipe *pipe, enum fd_param_id param,
       return query_param(pipe, MSM_PARAM_SUSPENDS, value);
    case FD_VA_SIZE:
       return query_param(pipe, MSM_PARAM_VA_SIZE, value);
+   case FD_UCHE_TRAP_BASE:
+      return query_param(pipe, MSM_PARAM_UCHE_TRAP_BASE, value);
    default:
       ERROR_MSG("invalid param id: %d", param);
       return -1;
diff --git a/src/freedreno/drm/virtio/virtio_pipe.c b/src/freedreno/drm/virtio/virtio_pipe.c
index cdeb913..d00026c 100644
--- a/src/freedreno/drm/virtio/virtio_pipe.c
+++ b/src/freedreno/drm/virtio/virtio_pipe.c
@@ -88,6 +88,8 @@ virtio_pipe_get_param(struct fd_pipe *pipe, enum fd_param_id param,
    case FD_VA_SIZE:
       *value = virtio_dev->vdrm->caps.u.msm.va_size;
       return 0;
+   case FD_UCHE_TRAP_BASE:
+      return query_param(pipe, MSM_PARAM_UCHE_TRAP_BASE, value);
    default:
       ERROR_MSG("invalid param id: %d", param);
       return -1;
diff --git a/src/freedreno/ir3/ir3_compiler.h b/src/freedreno/ir3/ir3_compiler.h
index 0d702a6..61b3aa5 100644
--- a/src/freedreno/ir3/ir3_compiler.h
+++ b/src/freedreno/ir3/ir3_compiler.h
@@ -54,6 +54,8 @@ struct ir3_compiler_options {
 
    /* "dual_color_blend_by_location" workaround is enabled: */
    bool dual_color_blend_by_location;
+
+   uint64_t uche_trap_base;
 };
 
 struct ir3_compiler {
diff --git a/src/freedreno/ir3/ir3_nir.c b/src/freedreno/ir3/ir3_nir.c
index 3c8fb8a..55ff840 100644
--- a/src/freedreno/ir3/ir3_nir.c
+++ b/src/freedreno/ir3/ir3_nir.c
@@ -548,6 +548,47 @@ ir3_nir_lower_array_sampler(nir_shader *shader)
       nir_metadata_control_flow, NULL);
 }
 
+static bool
+lower_shader_clock(struct nir_builder *b, nir_intrinsic_instr *instr, void *data)
+{
+   if (instr->intrinsic != nir_intrinsic_shader_clock)
+      return false;
+
+   uint64_t uche_trap_base = *(uint64_t *)data;
+
+   b->cursor = nir_before_instr(&instr->instr);
+   nir_def *clock, *undef;
+
+   nir_push_if(b, nir_elect(b, 1));
+   {
+      /* ALWAYSON counter is mapped to this address. */
+      nir_def *base_addr =
+         nir_unpack_64_2x32(b, nir_imm_int64(b, uche_trap_base));
+      /* Reading _LO first presumably latches _HI making the read atomic. */
+      nir_def *clock_lo =
+         nir_load_global_ir3(b, 1, 32, base_addr, nir_imm_int(b, 0));
+      nir_def *clock_hi =
+         nir_load_global_ir3(b, 1, 32, base_addr, nir_imm_int(b, 1));
+      clock = nir_vec2(b, clock_lo, clock_hi);
+   }
+   nir_push_else(b, NULL);
+   {
+      undef = nir_undef(b, 2, 32);
+   }
+   nir_pop_if(b, NULL);
+
+   clock = nir_read_first_invocation(b, nir_if_phi(b, clock, undef));
+   nir_def_replace(&instr->def, clock);
+   return true;
+}
+
+static bool
+ir3_nir_lower_shader_clock(nir_shader *shader, uint64_t uche_trap_base)
+{
+   return nir_shader_intrinsics_pass(shader, lower_shader_clock,
+                                     nir_metadata_none, &uche_trap_base);
+}
+
 void
 ir3_finalize_nir(struct ir3_compiler *compiler,
                  const struct ir3_shader_nir_options *options,
@@ -590,6 +631,10 @@ ir3_finalize_nir(struct ir3_compiler *compiler,
    if (compiler->array_index_add_half)
       OPT_V(s, ir3_nir_lower_array_sampler);
 
+   if (compiler->gen >= 6) {
+      OPT_V(s, ir3_nir_lower_shader_clock, compiler->options.uche_trap_base);
+   }
+
    OPT_V(s, nir_lower_is_helper_invocation);
 
    ir3_optimize_loop(compiler, options, s);
diff --git a/src/freedreno/vulkan/msm_kgsl.h b/src/freedreno/vulkan/msm_kgsl.h
index 8e3fc78..48a70d5 100644
--- a/src/freedreno/vulkan/msm_kgsl.h
+++ b/src/freedreno/vulkan/msm_kgsl.h
@@ -1,3 +1,9 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
+/*
+ * Copyright (c) 2018-2021, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2022-2023, Qualcomm Innovation Center, Inc. All rights reserved.
+ */
+
 #ifndef _UAPI_MSM_KGSL_H
 #define _UAPI_MSM_KGSL_H
 
@@ -7,7 +13,7 @@
 /*
  * The KGSL version has proven not to be very useful in userspace if features
  * are cherry picked into other trees out of order so it is frozen as of 3.14.
- * It is left here for backwards compatabilty and as a reminder that
+ * It is left here for backward compatibility and as a reminder that
  * software releases are never linear. Also, I like pie.
  */
 
@@ -69,6 +75,8 @@
 #define KGSL_CONTEXT_TYPE_UNKNOWN	0x1E
 
 #define KGSL_CONTEXT_INVALIDATE_ON_FAULT 0x10000000
+#define KGSL_CONTEXT_LPAC 0x20000000
+#define KGSL_CONTEXT_FAULT_INFO	  0x40000000
 
 #define KGSL_CONTEXT_INVALID 0xffffffff
 
@@ -94,6 +102,9 @@
 #define KGSL_CMDBATCH_SYNC		KGSL_CONTEXT_SYNC           /* 0x400 */
 #define KGSL_CMDBATCH_PWR_CONSTRAINT	KGSL_CONTEXT_PWR_CONSTRAINT /* 0x800 */
 #define KGSL_CMDBATCH_SPARSE	    0x1000 /* 0x1000 */
+/* RECURRING bits must be set for LSR workload with IOCTL_KGSL_RECURRING_COMMAND. */
+#define KGSL_CMDBATCH_START_RECURRING	0x00100000
+#define KGSL_CMDBATCH_STOP_RECURRING	0x00200000
 
 /*
  * Reserve bits [16:19] and bits [28:31] for possible bits shared between
@@ -117,14 +128,15 @@
 /* Flags for GPU command sync points */
 #define KGSL_CMD_SYNCPOINT_TYPE_TIMESTAMP 0
 #define KGSL_CMD_SYNCPOINT_TYPE_FENCE 1
+#define KGSL_CMD_SYNCPOINT_TYPE_TIMELINE 2
 
 /* --- Memory allocation flags --- */
 
 /* General allocation hints */
-#define KGSL_MEMFLAGS_SECURE      0x00000008ULL
-#define KGSL_MEMFLAGS_GPUREADONLY 0x01000000U
-#define KGSL_MEMFLAGS_GPUWRITEONLY 0x02000000U
-#define KGSL_MEMFLAGS_FORCE_32BIT 0x100000000ULL
+#define KGSL_MEMFLAGS_SECURE       (1ULL << 3)
+#define KGSL_MEMFLAGS_GPUREADONLY  (1ULL << 24)
+#define KGSL_MEMFLAGS_GPUWRITEONLY (1ULL << 25)
+#define KGSL_MEMFLAGS_FORCE_32BIT  (1ULL << 32)
 
 /* Flag for binding all the virt range to single phys data */
 #define KGSL_SPARSE_BIND_MULTIPLE_TO_PHYS 0x400000000ULL
@@ -140,10 +152,13 @@
 #define KGSL_CACHEMODE_WRITETHROUGH 2
 #define KGSL_CACHEMODE_WRITEBACK 3
 
-#define KGSL_MEMFLAGS_USE_CPU_MAP 0x10000000ULL
-#define KGSL_MEMFLAGS_SPARSE_PHYS 0x20000000ULL
-#define KGSL_MEMFLAGS_SPARSE_VIRT 0x40000000ULL
-#define KGSL_MEMFLAGS_IOCOHERENT  0x80000000ULL
+#define KGSL_MEMFLAGS_USE_CPU_MAP     (1ULL << 28)
+#define KGSL_MEMFLAGS_SPARSE_PHYS     (1ULL << 29)
+#define KGSL_MEMFLAGS_SPARSE_VIRT     (1ULL << 30)
+#define KGSL_MEMFLAGS_IOCOHERENT      (1ULL << 31)
+#define KGSL_MEMFLAGS_GUARD_PAGE      (1ULL << 33)
+#define KGSL_MEMFLAGS_VBO             (1ULL << 34)
+#define KGSL_MEMFLAGS_VBO_NO_MAP_ZERO (1ULL << 35)
 
 /* Memory types for which allocations are made */
 #define KGSL_MEMTYPE_MASK		0x0000FF00
@@ -185,7 +200,7 @@ enum kgsl_user_mem_type {
 	KGSL_USER_MEM_TYPE_ADDR		= 0x00000002,
 	KGSL_USER_MEM_TYPE_ION		= 0x00000003,
 	/*
-	 * ION type is retained for backwards compatibility but Ion buffers are
+	 * ION type is retained for backward compatibility but ION buffers are
 	 * dma-bufs so try to use that naming if we can
 	 */
 	KGSL_USER_MEM_TYPE_DMABUF       = 0x00000003,
@@ -232,6 +247,7 @@ enum kgsl_user_mem_type {
 #define KGSL_UBWC_2_0	2
 #define KGSL_UBWC_3_0	3
 #define KGSL_UBWC_4_0	4
+#define KGSL_UBWC_5_0	5
 
 /*
  * Reset status values for context
@@ -261,12 +277,12 @@ struct kgsl_devinfo {
 	 * number 200, 205, 220, etc...
 	 */
 	unsigned int gpu_id;
-	size_t gmem_sizebytes;
+	__kernel_size_t gmem_sizebytes;
 };
 
 /*
  * struct kgsl_devmemstore - this structure defines the region of memory
- * that can be mmap()ed from this driver. The timestamp fields are __volatile__
+ * that can be mmap()ed from this driver. The timestamp fields are volatile
  * because they are written by the GPU
  * @soptimestamp: Start of pipeline timestamp written by GPU before the
  * commands in concern are processed
@@ -282,13 +298,13 @@ struct kgsl_devinfo {
  * @sbz5: Unused, kept for 8 byte alignment
  */
 struct kgsl_devmemstore {
-	__volatile__ unsigned int soptimestamp;
+	volatile unsigned int soptimestamp;
 	unsigned int sbz;
-	__volatile__ unsigned int eoptimestamp;
+	volatile unsigned int eoptimestamp;
 	unsigned int sbz2;
-	__volatile__ unsigned int preempted;
+	volatile unsigned int preempted;
 	unsigned int sbz3;
-	__volatile__ unsigned int ref_wait_ts;
+	volatile unsigned int ref_wait_ts;
 	unsigned int sbz4;
 	unsigned int current_context;
 	unsigned int sbz5;
@@ -334,11 +350,21 @@ enum kgsl_timestamp_type {
 #define KGSL_PROP_GAMING_BIN		0x26
 #define KGSL_PROP_QUERY_CAPABILITIES	0x27
 #define KGSL_PROP_CONTEXT_PROPERTY	0x28
+#define KGSL_PROP_GPU_MODEL		0x29
+#define KGSL_PROP_VK_DEVICE_ID		0x2A
+#define KGSL_PROP_IS_LPAC_ENABLED	0x2B
+#define KGSL_PROP_GPU_VA64_SIZE		0x2C
+#define KGSL_PROP_IS_RAYTRACING_ENABLED	0x2D
+#define KGSL_PROP_IS_FASTBLEND_ENABLED		0x2E
+#define KGSL_PROP_UCHE_TRAP_BASE	0x2F
+#define KGSL_PROP_IS_AQE_ENABLED	0x30
+#define KGSL_PROP_GPU_SECURE_VA_SIZE	0x31
+#define KGSL_PROP_GPU_SECURE_VA_INUSE	0x32
 
 /*
- * kgsl_capabilties_properties returns a list of supported properties.
+ * kgsl_capabilities_properties returns a list of supported properties.
  * If the user passes 0 for 'count' the kernel will set it to the number of
- * supported properties. The list is expected to be 'count * sizeof(uint32_t)'
+ * supported properties. The list is expected to be 'count * sizeof(__u32)'
  * bytes long. The kernel will return the actual number of entries copied into
  * list via 'count'.
  */
@@ -354,7 +380,7 @@ struct kgsl_capabilities_properties {
 #define KGSL_QUERY_CAPS_PROPERTIES 1
 
 /*
- * kgsl_capabilities allows the user to query kernel capabiilties. The 'data'
+ * kgsl_capabilities allows the user to query kernel capabilities. The 'data'
  * type should be set appropriately for the querytype (see above). Pass 0 to
  * 'size' and the kernel will set it to the expected size of 'data' that is
  * appropriate for querytype (in bytes).
@@ -367,18 +393,18 @@ struct kgsl_capabilities {
 
 struct kgsl_shadowprop {
 	unsigned long gpuaddr;
-	size_t size;
+	__kernel_size_t size;
 	unsigned int flags; /* contains KGSL_FLAGS_ values */
 };
 
 struct kgsl_qdss_stm_prop {
-	uint64_t gpuaddr;
-	uint64_t size;
+	__u64 gpuaddr;
+	__u64 size;
 };
 
 struct kgsl_qtimer_prop {
-	uint64_t gpuaddr;
-	uint64_t size;
+	__u64 gpuaddr;
+	__u64 size;
 };
 
 struct kgsl_version {
@@ -389,8 +415,8 @@ struct kgsl_version {
 };
 
 struct kgsl_sp_generic_mem {
-	uint64_t local;
-	uint64_t pvt;
+	__u64 local;
+	__u64 pvt;
 };
 
 struct kgsl_ucode_version {
@@ -416,6 +442,10 @@ struct kgsl_context_property_fault {
 	__u32 timestamp;
 };
 
+struct kgsl_gpu_model {
+	char gpu_model[32];
+};
+
 /* Context property sub types */
 #define KGSL_CONTEXT_PROP_FAULTS 1
 
@@ -460,7 +490,23 @@ struct kgsl_context_property_fault {
 #define KGSL_PERFCOUNTER_GROUP_GLC 0x24
 #define KGSL_PERFCOUNTER_GROUP_FCHE 0x25
 #define KGSL_PERFCOUNTER_GROUP_MHUB 0x26
-#define KGSL_PERFCOUNTER_GROUP_MAX 0x27
+#define KGSL_PERFCOUNTER_GROUP_GMU_XOCLK 0x27
+#define KGSL_PERFCOUNTER_GROUP_GMU_GMUCLK  0x28
+#define KGSL_PERFCOUNTER_GROUP_GMU_PERF  0x29
+#define KGSL_PERFCOUNTER_GROUP_SW 0x2a
+#define KGSL_PERFCOUNTER_GROUP_UFC 0x2b
+#define KGSL_PERFCOUNTER_GROUP_BV_CP 0x2c
+#define KGSL_PERFCOUNTER_GROUP_BV_PC 0x2d
+#define KGSL_PERFCOUNTER_GROUP_BV_VFD 0x2e
+#define KGSL_PERFCOUNTER_GROUP_BV_VPC 0x2f
+#define KGSL_PERFCOUNTER_GROUP_BV_TP 0x30
+#define KGSL_PERFCOUNTER_GROUP_BV_SP 0x31
+#define KGSL_PERFCOUNTER_GROUP_BV_UFC 0x32
+#define KGSL_PERFCOUNTER_GROUP_BV_TSE 0x33
+#define KGSL_PERFCOUNTER_GROUP_BV_RAS 0x34
+#define KGSL_PERFCOUNTER_GROUP_BV_LRZ 0x35
+#define KGSL_PERFCOUNTER_GROUP_BV_HLSQ 0x36
+#define KGSL_PERFCOUNTER_GROUP_MAX 0x37
 
 #define KGSL_PERFCOUNTER_NOT_USED 0xFFFFFFFF
 #define KGSL_PERFCOUNTER_BROKEN 0xFFFFFFFE
@@ -469,7 +515,7 @@ struct kgsl_context_property_fault {
 struct kgsl_ibdesc {
 	unsigned long gpuaddr;
 	unsigned long __pad;
-	size_t sizedwords;
+	__kernel_size_t sizedwords;
 	unsigned int ctrl;
 };
 
@@ -489,11 +535,11 @@ struct kgsl_ibdesc {
  * execution time
  */
 struct kgsl_cmdbatch_profiling_buffer {
-	uint64_t wall_clock_s;
-	uint64_t wall_clock_ns;
-	uint64_t gpu_ticks_queued;
-	uint64_t gpu_ticks_submitted;
-	uint64_t gpu_ticks_retired;
+	__u64 wall_clock_s;
+	__u64 wall_clock_ns;
+	__u64 gpu_ticks_queued;
+	__u64 gpu_ticks_submitted;
+	__u64 gpu_ticks_retired;
 };
 
 /* ioctls */
@@ -513,7 +559,7 @@ struct kgsl_cmdbatch_profiling_buffer {
 struct kgsl_device_getproperty {
 	unsigned int type;
 	void *value;
-	size_t sizebytes;
+	__kernel_size_t sizebytes;
 };
 
 #define IOCTL_KGSL_DEVICE_GETPROPERTY \
@@ -629,8 +675,8 @@ struct kgsl_drawctxt_destroy {
 struct kgsl_map_user_mem {
 	int fd;
 	unsigned long gpuaddr;   /*output param */
-	size_t len;
-	size_t offset;
+	__kernel_size_t len;
+	__kernel_size_t offset;
 	unsigned long hostptr;   /*input param */
 	enum kgsl_user_mem_type memtype;
 	unsigned int flags;
@@ -776,7 +822,7 @@ struct kgsl_cmdwindow_write {
 
 struct kgsl_gpumem_alloc {
 	unsigned long gpuaddr; /* output param */
-	size_t size;
+	__kernel_size_t size;
 	unsigned int flags;
 };
 
@@ -785,7 +831,7 @@ struct kgsl_gpumem_alloc {
 
 struct kgsl_cff_syncmem {
 	unsigned long gpuaddr;
-	size_t len;
+	__kernel_size_t len;
 	unsigned int __pad[2]; /* For future binary compatibility */
 };
 
@@ -803,7 +849,7 @@ struct kgsl_timestamp_event {
 	unsigned int timestamp;  /* Timestamp to trigger event on */
 	unsigned int context_id; /* Context for the timestamp */
 	void *priv;	 /* Pointer to the event specific blob */
-	size_t len;              /* Size of the event specific blob */
+	__kernel_size_t len;              /* Size of the event specific blob */
 };
 
 #define IOCTL_KGSL_TIMESTAMP_EVENT_OLD \
@@ -858,8 +904,8 @@ struct kgsl_timestamp_event_fence {
 struct kgsl_gpumem_alloc_id {
 	unsigned int id;
 	unsigned int flags;
-	size_t size;
-	size_t mmapsize;
+	__kernel_size_t size;
+	__kernel_size_t mmapsize;
 	unsigned long gpuaddr;
 /* private: reserved for future use*/
 	unsigned long __pad[2];
@@ -904,8 +950,8 @@ struct kgsl_gpumem_get_info {
 	unsigned long gpuaddr;
 	unsigned int id;
 	unsigned int flags;
-	size_t size;
-	size_t mmapsize;
+	__kernel_size_t size;
+	__kernel_size_t mmapsize;
 	unsigned long useraddr;
 /* private: reserved for future use*/
 	unsigned long __pad[4];
@@ -932,8 +978,8 @@ struct kgsl_gpumem_sync_cache {
 	unsigned long gpuaddr;
 	unsigned int id;
 	unsigned int op;
-	size_t offset;
-	size_t length;
+	__kernel_size_t offset;
+	__kernel_size_t length;
 };
 
 #define KGSL_GPUMEM_CACHE_CLEAN (1 << 0)
@@ -945,7 +991,7 @@ struct kgsl_gpumem_sync_cache {
 #define KGSL_GPUMEM_CACHE_FLUSH \
 	(KGSL_GPUMEM_CACHE_CLEAN | KGSL_GPUMEM_CACHE_INV)
 
-/* Flag to ensure backwards compatibility of kgsl_gpumem_sync_cache struct */
+/* Flag to ensure backward compatibility of kgsl_gpumem_sync_cache struct */
 #define KGSL_GPUMEM_CACHE_RANGE (1 << 31U)
 
 #define IOCTL_KGSL_GPUMEM_SYNC_CACHE \
@@ -1002,8 +1048,8 @@ struct kgsl_perfcounter_put {
 /**
  * struct kgsl_perfcounter_query - argument to IOCTL_KGSL_PERFCOUNTER_QUERY
  * @groupid: Performance counter group ID
- * @countable: Return active countables array
- * @size: Size of active countables array
+ * @countables: Return active countables array
+ * @count: Number of entries in @countables
  * @max_counters: Return total number counters for the group ID
  *
  * Query the available performance counters given a groupid.  The array
@@ -1030,11 +1076,10 @@ struct kgsl_perfcounter_query {
 	_IOWR(KGSL_IOC_TYPE, 0x3A, struct kgsl_perfcounter_query)
 
 /**
- * struct kgsl_perfcounter_query - argument to IOCTL_KGSL_PERFCOUNTER_QUERY
+ * struct kgsl_perfcounter_read_group - argument to IOCTL_KGSL_PERFCOUNTER_QUERY
  * @groupid: Performance counter group IDs
  * @countable: Performance counter countable IDs
  * @value: Return performance counter reads
- * @size: Size of all arrays (groupid/countable pair and return value)
  *
  * Read in the current value of a performance counter given by the groupid
  * and countable.
@@ -1097,6 +1142,21 @@ struct kgsl_cmd_syncpoint_fence {
 	int fd;
 };
 
+/*
+ * struct kgsl_cmd_syncpoint_timeline
+ * @timelines: Address of an array of &struct kgsl_timeline_val
+ * @count: Number of entries in @timelines
+ * @timelines_size: Size of each entry in @timelines
+ *
+ * Define a syncpoint for a number of timelines.  This syncpoint will
+ * be satisfied when all of the specified timelines are signaled.
+ */
+struct kgsl_cmd_syncpoint_timeline {
+	__u64 timelines;
+	__u32 count;
+	__u32 timelines_size;
+};
+
 /**
  * struct kgsl_cmd_syncpoint - Define a sync point for a command batch
  * @type: type of sync point defined here
@@ -1109,7 +1169,7 @@ struct kgsl_cmd_syncpoint_fence {
 struct kgsl_cmd_syncpoint {
 	int type;
 	void *priv;
-	size_t size;
+	__kernel_size_t size;
 };
 
 /* Flag to indicate that the cmdlist may contain memlists */
@@ -1163,7 +1223,7 @@ struct kgsl_device_constraint {
 	unsigned int type;
 	unsigned int context_id;
 	void *data;
-	size_t size;
+	__kernel_size_t size;
 };
 
 /* Constraint Type*/
@@ -1264,8 +1324,8 @@ struct kgsl_syncsource_signal_fence {
  * @id: ID of the GPU object to sync
  */
 struct kgsl_cff_sync_gpuobj {
-	uint64_t offset;
-	uint64_t length;
+	__u64 offset;
+	__u64 length;
 	unsigned int id;
 };
 
@@ -1283,13 +1343,13 @@ struct kgsl_cff_sync_gpuobj {
  * @metadata: Pointer to the user specified metadata to store for the object
  */
 struct kgsl_gpuobj_alloc {
-	uint64_t size;
-	uint64_t flags;
-	uint64_t va_len;
-	uint64_t mmapsize;
+	__u64 size;
+	__u64 flags;
+	__u64 va_len;
+	__u64 mmapsize;
 	unsigned int id;
 	unsigned int metadata_len;
-	uint64_t metadata;
+	__u64 metadata;
 };
 
 /* Let the user know that this header supports the gpuobj metadata */
@@ -1309,8 +1369,8 @@ struct kgsl_gpuobj_alloc {
  * @len: Length of the data passed in priv
  */
 struct kgsl_gpuobj_free {
-	uint64_t flags;
-	uint64_t priv;
+	__u64 flags;
+	__u64 priv;
 	unsigned int id;
 	unsigned int type;
 	unsigned int len;
@@ -1353,11 +1413,11 @@ struct kgsl_gpu_event_fence {
  * id - GPU object ID of the object to query
  */
 struct kgsl_gpuobj_info {
-	uint64_t gpuaddr;
-	uint64_t flags;
-	uint64_t size;
-	uint64_t va_len;
-	uint64_t va_addr;
+	__u64 gpuaddr;
+	__u64 flags;
+	__u64 size;
+	__u64 va_len;
+	__u64 va_addr;
 	unsigned int id;
 };
 
@@ -1373,9 +1433,9 @@ struct kgsl_gpuobj_info {
  * @id: Returns the ID of the new GPU object
  */
 struct kgsl_gpuobj_import {
-	uint64_t priv;
-	uint64_t priv_len;
-	uint64_t flags;
+	__u64 priv;
+	__u64 priv_len;
+	__u64 flags;
 	unsigned int type;
 	unsigned int id;
 };
@@ -1393,7 +1453,7 @@ struct kgsl_gpuobj_import_dma_buf {
  * @virtaddr: Virtual address of the object to import
  */
 struct kgsl_gpuobj_import_useraddr {
-	uint64_t virtaddr;
+	__u64 virtaddr;
 };
 
 #define IOCTL_KGSL_GPUOBJ_IMPORT \
@@ -1408,8 +1468,8 @@ struct kgsl_gpuobj_import_useraddr {
  */
 
 struct kgsl_gpuobj_sync_obj {
-	uint64_t offset;
-	uint64_t length;
+	__u64 offset;
+	__u64 length;
 	unsigned int id;
 	unsigned int op;
 };
@@ -1422,7 +1482,7 @@ struct kgsl_gpuobj_sync_obj {
  */
 
 struct kgsl_gpuobj_sync {
-	uint64_t objs;
+	__u64 objs;
 	unsigned int obj_len;
 	unsigned int count;
 };
@@ -1439,9 +1499,9 @@ struct kgsl_gpuobj_sync {
  * @id - GPU command object ID
  */
 struct kgsl_command_object {
-	uint64_t offset;
-	uint64_t gpuaddr;
-	uint64_t size;
+	__u64 offset;
+	__u64 gpuaddr;
+	__u64 size;
 	unsigned int flags;
 	unsigned int id;
 };
@@ -1453,35 +1513,35 @@ struct kgsl_command_object {
  * @type: type of sync point defined here
  */
 struct kgsl_command_syncpoint {
-	uint64_t priv;
-	uint64_t size;
+	__u64 priv;
+	__u64 size;
 	unsigned int type;
 };
 
 /**
- * struct kgsl_command_object - Argument for IOCTL_KGSL_GPU_COMMAND
+ * struct kgsl_gpu_command - Argument for IOCTL_KGSL_GPU_COMMAND
  * @flags: Current flags for the object
  * @cmdlist: List of kgsl_command_objects for submission
- * @cmd_size: Size of kgsl_command_objects structure
+ * @cmdsize: Size of kgsl_command_objects structure
  * @numcmds: Number of kgsl_command_objects in command list
  * @objlist: List of kgsl_command_objects for tracking
- * @obj_size: Size of kgsl_command_objects structure
+ * @objsize: Size of kgsl_command_objects structure
  * @numobjs: Number of kgsl_command_objects in object list
  * @synclist: List of kgsl_command_syncpoints
- * @sync_size: Size of kgsl_command_syncpoint structure
+ * @syncsize: Size of kgsl_command_syncpoint structure
  * @numsyncs: Number of kgsl_command_syncpoints in syncpoint list
- * @context_id: Context ID submittin ghte kgsl_gpu_command
+ * @context_id: Context ID submitting the kgsl_gpu_command
  * @timestamp: Timestamp for the submitted commands
  */
 struct kgsl_gpu_command {
-	uint64_t flags;
-	uint64_t cmdlist;
+	__u64 flags;
+	__u64 cmdlist;
 	unsigned int cmdsize;
 	unsigned int numcmds;
-	uint64_t objlist;
+	__u64 objlist;
 	unsigned int objsize;
 	unsigned int numobjs;
-	uint64_t synclist;
+	__u64 synclist;
 	unsigned int syncsize;
 	unsigned int numsyncs;
 	unsigned int context_id;
@@ -1509,7 +1569,7 @@ struct kgsl_gpu_command {
  * returned back.
  */
 struct kgsl_preemption_counters_query {
-	uint64_t counters;
+	__u64 counters;
 	unsigned int size_user;
 	unsigned int size_priority_level;
 	unsigned int max_priority_level;
@@ -1533,8 +1593,8 @@ struct kgsl_preemption_counters_query {
 #define KGSL_GPUOBJ_SET_INFO_TYPE (1 << 1)
 
 struct kgsl_gpuobj_set_info {
-	uint64_t flags;
-	uint64_t metadata;
+	__u64 flags;
+	__u64 metadata;
 	unsigned int id;
 	unsigned int metadata_len;
 	unsigned int type;
@@ -1551,9 +1611,9 @@ struct kgsl_gpuobj_set_info {
  * @id: Returned ID for this allocation
  */
 struct kgsl_sparse_phys_alloc {
-	uint64_t size;
-	uint64_t pagesize;
-	uint64_t flags;
+	__u64 size;
+	__u64 pagesize;
+	__u64 flags;
 	unsigned int id;
 };
 
@@ -1580,10 +1640,10 @@ struct kgsl_sparse_phys_free {
  * @gpuaddr: Returned GPU address for this allocation
  */
 struct kgsl_sparse_virt_alloc {
-	uint64_t size;
-	uint64_t pagesize;
-	uint64_t flags;
-	uint64_t gpuaddr;
+	__u64 size;
+	__u64 pagesize;
+	__u64 flags;
+	__u64 gpuaddr;
 	unsigned int id;
 };
 
@@ -1610,10 +1670,10 @@ struct kgsl_sparse_virt_free {
  * @id: Physical ID to bind (bind only)
  */
 struct kgsl_sparse_binding_object {
-	uint64_t virtoffset;
-	uint64_t physoffset;
-	uint64_t size;
-	uint64_t flags;
+	__u64 virtoffset;
+	__u64 physoffset;
+	__u64 size;
+	__u64 flags;
 	unsigned int id;
 };
 
@@ -1626,7 +1686,7 @@ struct kgsl_sparse_binding_object {
  *
  */
 struct kgsl_sparse_bind {
-	uint64_t list;
+	__u64 list;
 	unsigned int id;
 	unsigned int size;
 	unsigned int count;
@@ -1650,9 +1710,9 @@ struct kgsl_sparse_bind {
  * @id: Virtual ID to bind/unbind
  */
 struct kgsl_gpu_sparse_command {
-	uint64_t flags;
-	uint64_t sparselist;
-	uint64_t synclist;
+	__u64 flags;
+	__u64 sparselist;
+	__u64 synclist;
 	unsigned int sparsesize;
 	unsigned int numsparse;
 	unsigned int syncsize;
@@ -1665,4 +1725,436 @@ struct kgsl_gpu_sparse_command {
 #define IOCTL_KGSL_GPU_SPARSE_COMMAND \
 	_IOWR(KGSL_IOC_TYPE, 0x55, struct kgsl_gpu_sparse_command)
 
+#define KGSL_GPUMEM_RANGE_OP_BIND 1
+#define KGSL_GPUMEM_RANGE_OP_UNBIND 2
+
+/**
+ * struct kgsl_gpumem_bind_range - specifies a bind operation for a virtual
+ * buffer object
+ * @child_offset: Offset to the start of memory within the child buffer object
+ * (not used for KGSL_GPUMEM_RANGE_OP_UNBIND operations)
+ * @target_offset: GPU address offset within the target VBO
+ * @length: Amount of memory to map/unmap (in bytes)
+ * @child_id: The GPU buffer ID for the child object to map/unmap in the VBO
+ * @op: One of KGSL_GPUMEM_RANGE_OP_BIND or KGSL_GPUMEM_RANGE_OP_UNBIND
+ *
+ * This defines a specific bind operation to a virtual buffer object specified
+ * in &struct kgsl_gpumem_bind_ranges. When @op is KGSL_GPUMEM_RANGE_OP_BIND the
+ * physical memory starting at @child_offset in the memory object identified by
+ * @child_id will be mapped into the target virtual buffer object starting at
+ * @offset for @length bytes.
+ *
+ * When @op is KGSL_GPUMEM_RANGE_OP_UNBIND any entries in the target virtual
+ * buffer object between @offset and @length that belong to @child_id will be
+ * removed.
+ */
+struct kgsl_gpumem_bind_range {
+	__u64 child_offset;
+	__u64 target_offset;
+	__u64 length;
+	__u32 child_id;
+	__u32 op;
+};
+
+#define KGSL_GPUMEM_BIND_ASYNC		(1UL << 0)
+#define KGSL_GPUMEM_BIND_FENCE_OUT	(1UL << 1)
+
+/**
+ * struct kgsl_gpumem_bind_ranges - Argument to IOCTL_KGSL_GPUMEM_BIND_RANGES to
+ * either map or unmap a child buffer object into a virtual buffer object.
+ * @ranges: User memory pointer to an array of range operations of type &struct
+ * kgsl_gpumem_bind_range
+ * @ranges_nents: Number of entries in @ranges
+ * @ranges_size: Size of each entry in @ranges in bytes
+ * @id: GPU buffer object identifier for the target virtual buffer object
+ * @flags: Bitmap of KGSL_GPUMEM_BIND_ASYNC and KGSL_GPUMEM_BIND_FENCE_OUT
+ * @fence_id: If KGSL_GPUMEM_BIND_FENCE_OUT is set in @flags contains the
+ * identifier for the sync fence that will be signaled after the operation
+ * completes
+ *
+ * Describes a number of range operations to perform on a virtual buffer object
+ * identified by @id. Ranges should be a __u64 representation of an array of
+ * &struct kgsl_gpumem_bind_range entries. @ranges_nents will contain the number
+ * of entries in the array, and @ranges_size will contain the size of each entry
+ * in the array. If KGSL_GPUMEM_BIND_ASYNC is set the operation will be
+ * performed asynchronously and the operation will immediately return to the
+ * user. Otherwise the calling context will block until the operation has
+ * completed.
+ *
+ * If KGSL_GPUMEM_BIND_ASYNC and KGSL_GPUMEM_BIND_FENCE_OUT are both set a sync
+ * fence will be created and returned in @fence_id. The fence will be signaled
+ * when the bind operation has completed.
+ */
+struct kgsl_gpumem_bind_ranges {
+	__u64 ranges;
+	__u32 ranges_nents;
+	__u32 ranges_size;
+	__u32 id;
+	__u32 flags;
+	int fence_id;
+	/* private: 64 bit compatibility */
+	__u32 padding;
+};
+
+#define IOCTL_KGSL_GPUMEM_BIND_RANGES \
+	_IOWR(KGSL_IOC_TYPE, 0x56, struct kgsl_gpumem_bind_ranges)
+
+#define KGSL_GPU_AUX_COMMAND_BIND	(1 << 0)
+#define KGSL_GPU_AUX_COMMAND_TIMELINE	(1 << 1)
+/* Reuse the same flag that GPU COMMAND uses */
+#define KGSL_GPU_AUX_COMMAND_SYNC	KGSL_CMDBATCH_SYNC
+
+/**
+ * struct kgsl_gpu_aux_command_bind - Descriptor for a GPU AUX bind command
+ * @rangeslist: Pointer to a list of &struct kgsl_gpumem_bind_range items
+ * @numranges Number of entries in @rangeslist
+ * @rangesize: Size of each entry in @rangeslist
+ * @target: The GPU memory ID for the target virtual buffer object
+ *
+ * Describe a GPU AUX command to bind ranges in a virtual buffer object.
+ * @rangeslist points to a &struct kgsl_gpumem_bind_ranges which is the same
+ * struct that is used by IOCTl_KGSL_GPUMEM_BIND_RANGES. @numrages is the size
+ * of the array in @rangeslist and @rangesize is the size of each entity in
+ * @rangeslist. @target points to the GPU ID for the target VBO object.
+ */
+struct kgsl_gpu_aux_command_bind {
+	__u64 rangeslist;
+	__u64 numranges;
+	__u64 rangesize;
+	__u32 target;
+/* private: Padding for 64 bit compatibility */
+	__u32 padding;
+};
+
+/**
+ * struct kgsl_gpu_aux_command_generic - Container for an AUX command
+ * @priv: Pointer to the type specific buffer
+ * @size: Size of the type specific buffer
+ * @type: type of sync point defined here
+ *
+ * Describes a generic container for GPU aux commands. @priv is a user pointer
+ * to the command struct matching @type of size @size.
+ */
+struct kgsl_gpu_aux_command_generic {
+	__u64 priv;
+	__u64 size;
+	__u32 type;
+/* private: Padding for 64 bit compatibility */
+	__u32 padding;
+};
+
+/**
+ * struct kgsl_gpu_aux_command - Argument for IOCTL_KGSL_GPU_AUX_COMMAND
+ * @flags: flags for the object
+ * @cmdlist: List of &struct kgsl_gpu_aux_command_generic objects
+ * @cmd_size: Size of each entry in @cmdlist
+ * @numcmds: Number of entries in @cmdlist
+ * @synclist: List of &struct kgsl_command_syncpoint objects
+ * @syncsize: Size of each entry in @synclist
+ * @numsyncs: Number of entries in @synclist
+ * @context_id: ID of the context submitting the aux command
+ * @timestamp: Timestamp for the command submission
+ *
+ * Describe a GPU auxiliary command. Auxiliary commands are tasks that are not
+ * performed on hardware but can be queued like normal GPU commands. Like GPU
+ * commands AUX commands are assigned a timestamp and processed in order in the
+ * queue. They can also have standard sync objects attached. The only
+ * difference is that AUX commands usually perform some sort of administrative
+ * task in the CPU and are retired in the dispatcher.
+ *
+ * For bind operations flags must have one of the KGSL_GPU_AUX_COMMAND_* flags
+ * set. If sync objects are attached KGSL_GPU_AUX_COMMAND_SYNC must be set.
+ * @cmdlist points to an array of &struct kgsl_gpu_aux_command_generic structs
+ * which in turn will have a pointer to a specific command type.
+ * @numcmds is the number of commands in the list and @cmdsize is the size
+ * of each entity in @cmdlist.
+ *
+ * If KGSL_GPU_AUX_COMMAND_SYNC is specified @synclist will point to an array of
+ * &struct kgsl_command_syncpoint items in the same fashion as a GPU hardware
+ * command. @numsyncs and @syncsize describe the list.
+ *
+ * @context_id is the context that is submitting the command and @timestamp
+ * contains the timestamp for the operation.
+ */
+struct kgsl_gpu_aux_command {
+	__u64 flags;
+	__u64 cmdlist;
+	__u32 cmdsize;
+	__u32 numcmds;
+	__u64 synclist;
+	__u32 syncsize;
+	__u32 numsyncs;
+	__u32 context_id;
+	__u32 timestamp;
+};
+
+#define IOCTL_KGSL_GPU_AUX_COMMAND \
+	_IOWR(KGSL_IOC_TYPE, 0x57, struct kgsl_gpu_aux_command)
+
+/**
+ * struct kgsl_timeline_create - Argument for IOCTL_KGSL_TIMELINE_CREATE
+ * @seqno: Initial sequence number for the timeline
+ * @id: Timeline identifier [out]
+ *
+ * Create a new semaphore timeline and return the identifier in @id.
+ * The identifier is global for the device and can be used to
+ * identify the timeline in all subsequent commands.
+ */
+struct kgsl_timeline_create {
+	__u64 seqno;
+	__u32 id;
+/* private: padding for 64 bit compatibility */
+	__u32 padding;
+};
+
+#define IOCTL_KGSL_TIMELINE_CREATE \
+	_IOWR(KGSL_IOC_TYPE, 0x58, struct kgsl_timeline_create)
+
+/**
+ * struct kgsl_timeline_val - A container to store a timeline/sequence number
+ * pair.
+ * @seqno: Sequence number to signal/query
+ * @timeline: The timeline identifier to signal/query
+ *
+ * A container to store a timeline/seqno pair used by the query and signal
+ * ioctls.
+ */
+struct kgsl_timeline_val {
+	__u64 seqno;
+	__u32 timeline;
+/* private: padding for 64 bit compatibility */
+	__u32 padding;
+};
+
+#define KGSL_TIMELINE_WAIT_ALL 1
+#define KGSL_TIMELINE_WAIT_ANY 2
+
+/**
+ * struct kgsl_timeline_wait - Argument for IOCTL_KGSL_TIMELINE_WAIT
+ * @tv_sec: Number of seconds to wait for the signal
+ * @tv_nsec: Number of nanoseconds to wait for the signal
+ * @timelines: Address of an array of &struct kgsl_timeline_val entries
+ * @count: Number of entries in @timeline
+ * @timelines_size: Size of each entry in @timelines
+ * @flags: One of KGSL_TIMELINE_WAIT_ALL or KGSL_TIMELINE_WAIT_ANY
+ *
+ * Wait for the timelines listed in @timelines to be signaled. If @flags is
+ * equal to KGSL_TIMELINE_WAIT_ALL then wait for all timelines or if
+ * KGSL_TIMELINE_WAIT_ANY is specified then wait for any of the timelines to
+ * signal. @tv_sec and @tv_nsec indicates the number of seconds and nanoseconds
+ * that the process should be blocked waiting for the signal.
+ */
+struct kgsl_timeline_wait {
+	__s64 tv_sec;
+	__s64 tv_nsec;
+	__u64 timelines;
+	__u32 count;
+	__u32 timelines_size;
+	__u32 flags;
+/* private: padding for 64 bit compatibility */
+	__u32 padding;
+};
+
+#define IOCTL_KGSL_TIMELINE_WAIT \
+	_IOW(KGSL_IOC_TYPE, 0x59, struct kgsl_timeline_wait)
+
+#define IOCTL_KGSL_TIMELINE_QUERY \
+	_IOWR(KGSL_IOC_TYPE, 0x5A, struct kgsl_timeline_val)
+
+/**
+ * struct kgsl_timeline_signal - argument for IOCTL_KGSL_TIMELINE_SIGNAL
+ * @timelines: Address of an array of &struct kgsl_timeline_val entries
+ * @count: Number of entries in @timelines
+ * @timelines_size: Size of each entry in @timelines
+ *
+ * Signal an array of timelines of type @struct kgsl_timeline_val.
+ */
+struct kgsl_timeline_signal {
+	__u64 timelines;
+	__u32 count;
+	__u32 timelines_size;
+};
+
+#define IOCTL_KGSL_TIMELINE_SIGNAL \
+	_IOW(KGSL_IOC_TYPE, 0x5B, struct kgsl_timeline_signal)
+
+/**
+ * struct kgsl_timeline_fence_get - argument for IOCTL_KGSL_TIMELINE_FENCE_GET
+ * @seqno: Sequence number for the fence
+ * @timeline: Timeline to create the fence on
+ * @handle: Contains the fence fd for a successful operation [out]
+ *
+ * Create a sync file descriptor for the seqnum on the timeline and return it in
+ * @handle.  Can be polled and queried just like any other sync file descriptor
+ */
+struct kgsl_timeline_fence_get {
+	__u64 seqno;
+	__u32 timeline;
+	int handle;
+};
+
+#define IOCTL_KGSL_TIMELINE_FENCE_GET \
+	_IOWR(KGSL_IOC_TYPE, 0x5C, struct kgsl_timeline_fence_get)
+/**
+ * IOCTL_KGSL_TIMELINE_DESTROY takes a u32 identifier for the timeline to
+ * destroy
+ */
+#define IOCTL_KGSL_TIMELINE_DESTROY _IOW(KGSL_IOC_TYPE, 0x5D, __u32)
+
+/**
+ * struct kgsl_gpu_aux_command_timeline - An aux command for timeline signals
+ * @timelines: An array of &struct kgsl_timeline_val elements
+ * @count: The number of entries in @timelines
+ * @timelines_size: The size of each element in @timelines
+ *
+ * An aux command for timeline signals that can be pointed to by
+ * &struct kgsl_gpu_aux_command_generic when the type is
+ * KGSL_GPU_AUX_COMMAND_TIMELINE.
+ */
+struct kgsl_gpu_aux_command_timeline {
+	__u64 timelines;
+	__u32 count;
+	__u32 timelines_size;
+};
+
+/* Macros for fault type used in kgsl_fault structure */
+#define KGSL_FAULT_TYPE_NO_FAULT    0
+#define KGSL_FAULT_TYPE_PAGEFAULT   1
+#define KGSL_FAULT_TYPE_MAX         2
+
+/* Macros to be used in kgsl_pagefault_report structure */
+#define KGSL_PAGEFAULT_TYPE_NONE                  0
+#define KGSL_PAGEFAULT_TYPE_READ                  (1 << 0)
+#define KGSL_PAGEFAULT_TYPE_WRITE                 (1 << 1)
+#define KGSL_PAGEFAULT_TYPE_TRANSLATION           (1 << 2)
+#define KGSL_PAGEFAULT_TYPE_PERMISSION            (1 << 3)
+#define KGSL_PAGEFAULT_TYPE_EXTERNAL              (1 << 4)
+#define KGSL_PAGEFAULT_TYPE_TRANSACTION_STALLED   (1 << 5)
+
+/**
+ * struct kgsl_pagefault_report - Descriptor for each page fault
+ * @fault_addr: page fault address
+ * @fault_type: type of page fault
+ *
+ * Contains information about supported GPU page fault.
+ * Supported fault type: KGSL_PAGEFAULT_TYPE_*
+ */
+struct kgsl_pagefault_report {
+	__u64 fault_addr;
+	/* private: reserved for future use */
+	__u64 reserved[2];
+	__u32 fault_type;
+	/* private: padding for 64 bit compatibility */
+	__u32 __pad;
+};
+
+/**
+ * struct kgsl_fault - Descriptor for each GPU fault type
+ * @fault: User memory pointer to list of specific fault type
+ * @type: Type of gpu fault
+ * @count: Number of entries in @fault
+ * @size: Size of each entry in @fault in bytes
+ *
+ * Contains information about each GPU fault type. If user passes 0 for all the fields, KGSL
+ * will return the @count and @type of fault. Based on this, user can allocate a buffer for
+ * specific fault type, fill the @fault and specify the structure size of type specific fault
+ * in @size. User can walk through @fault list to parse the fault type specific information.
+ *
+ * Supported type: KGSL_FAULT_TYPE_*
+ */
+struct kgsl_fault {
+	__u64 fault;
+	__u32 type;
+	__u32 count;
+	__u32 size;
+	/* private: padding for 64 bit compatibility */
+	__u32 padding;
+};
+
+/**
+ * struct kgsl_fault_report - Container for list of GPU faults
+ * @faultlist: User memory pointer to list of fault descriptor &struct kgsl_fault
+ * @faultnents: Number of entries in @faultlist. Each entry corresponds to a fault type i.e.
+ * KGSL_FAULT_TYPE_*
+ * @faultsize: Size of each entry in @faultlist in bytes
+ * @context_id: ID of a KGSL context
+ *
+ * Returns a list of GPU faults for a context identified by @context_id. If the user specifies
+ * @context_id only, then KGSL will set the @faultnents to the number of fault types it has
+ * for that context.
+ *
+ * User is expected to allocate an array of @struct kgsl_fault with @faultnents number of entries
+ * and fill the @faultlist field. On calling @IOCTL_KGSL_GET_FAULT_REPORT, KGSL will return the
+ * type and count for each fault. Based on this, user needs to update the @kgsl_fault structure.
+ * Then, it should call the @IOCTL_KGSL_GET_FAULT_REPORT again for kernel to fill the fault
+ * information.
+ */
+struct kgsl_fault_report {
+	__u64 faultlist;
+	__u32 faultnents;
+	__u32 faultsize;
+	__u32 context_id;
+	/* private: padding for 64 bit compatibility */
+	__u32 padding;
+};
+
+#define IOCTL_KGSL_GET_FAULT_REPORT \
+	_IOWR(KGSL_IOC_TYPE, 0x5E, struct kgsl_fault_report)
+
+/**
+ * struct kgsl_recurring_object - Argument for IOCTL_KGSL_RECURRING_COMMAND
+ * @flags: Current flags for the object
+ * @cmdlist: List of kgsl_command_objects for submission
+ * @cmd_size: Size of kgsl_command_objects structure
+ * @numcmds: Number of kgsl_command_objects in command list
+ * @objlist: List of kgsl_command_objects for tracking
+ * @obj_size: Size of kgsl_command_objects structure
+ * @numobjs: Number of kgsl_command_objects in object list
+ * @context_id: Context ID submitting the kgsl_recurring_command
+ */
+struct kgsl_recurring_command {
+	__u64 flags;
+	__u64 cmdlist;
+	__u32 cmdsize;
+	__u32 numcmds;
+	__u64 objlist;
+	__u32 objsize;
+	__u32 numobjs;
+	__u32 context_id;
+	/* private: Padding for 64 bit compatibility */
+	__u32 padding;
+};
+
+#define IOCTL_KGSL_RECURRING_COMMAND \
+	_IOWR(KGSL_IOC_TYPE, 0x5F, struct kgsl_recurring_command)
+
+enum kgsl_calibrated_time_domain {
+	KGSL_CALIBRATED_TIME_DOMAIN_DEVICE = 0,
+	KGSL_CALIBRATED_TIME_DOMAIN_MONOTONIC = 1,
+	KGSL_CALIBRATED_TIME_DOMAIN_MONOTONIC_RAW = 2,
+	KGSL_CALIBRATED_TIME_DOMAIN_MAX,
+};
+
+/**
+ * struct kgsl_read_calibrated_timestamps - Argument for IOCTL_KGSL_READ_CALIBRATED_TIMESTAMPS
+ * @sources: List of time domains of type enum kgsl_calibrated_time_domain
+ * @ts: List of calibrated timestamps
+ * @deviation: Deviation between timestamp samples in nsecs
+ * @count: Number of timestamps to read
+ *
+ * Returns a list of calibrated timestamps corresponding to an input list of time domains to
+ * query.
+ */
+struct kgsl_read_calibrated_timestamps {
+	__u64 sources;
+	__u64 ts;
+	__u64 deviation;
+	__u32 count;
+	/* private: Padding for 64 bit compatibility */
+	__u32 padding;
+};
+
+#define IOCTL_KGSL_READ_CALIBRATED_TIMESTAMPS \
+	_IOWR(KGSL_IOC_TYPE, 0x60, struct kgsl_read_calibrated_timestamps)
+
 #endif /* _UAPI_MSM_KGSL_H */
diff --git a/src/freedreno/vulkan/tu_device.cc b/src/freedreno/vulkan/tu_device.cc
index 514487e..8f79d91 100644
--- a/src/freedreno/vulkan/tu_device.cc
+++ b/src/freedreno/vulkan/tu_device.cc
@@ -206,6 +206,7 @@ get_device_extensions(const struct tu_physical_device *device,
       .KHR_sampler_ycbcr_conversion = true,
       .KHR_separate_depth_stencil_layouts = true,
       .KHR_shader_atomic_int64 = device->info->a7xx.has_64b_ssbo_atomics,
+      .KHR_shader_clock = true,
       .KHR_shader_draw_parameters = true,
       .KHR_shader_expect_assume = true,
       .KHR_shader_float16_int8 = true,
@@ -508,6 +509,10 @@ tu_get_features(struct tu_physical_device *pdevice,
    /* VK_KHR_present_wait */
    features->presentWait = pdevice->vk.supported_extensions.KHR_present_wait;
 
+   /* VK_KHR_shader_clock */
+   features->shaderSubgroupClock = true;
+   features->shaderDeviceClock = true;
+
    /* VK_KHR_shader_expect_assume */
    features->shaderExpectAssume = true;
 
@@ -2469,6 +2474,7 @@ tu_CreateDevice(VkPhysicalDevice physicalDevice,
          .storage_16bit = physical_device->info->a6xx.storage_16bit,
          .storage_8bit = physical_device->info->a7xx.storage_8bit,
          .shared_push_consts = !TU_DEBUG(PUSH_CONSTS_PER_STAGE),
+         .uche_trap_base = physical_device->uche_trap_base,
       };
       device->compiler = ir3_compiler_create(
          NULL, &physical_device->dev_id, physical_device->info, &ir3_options);
diff --git a/src/freedreno/vulkan/tu_device.h b/src/freedreno/vulkan/tu_device.h
index 27652f8..c7c966d 100644
--- a/src/freedreno/vulkan/tu_device.h
+++ b/src/freedreno/vulkan/tu_device.h
@@ -110,6 +110,7 @@ struct tu_physical_device
    uint32_t vpc_attr_buf_size_gmem;
    uint32_t vpc_attr_buf_offset_bypass;
    uint32_t vpc_attr_buf_size_bypass;
+   uint64_t uche_trap_base;
 
    /* Amount of usable descriptor sets, this excludes any reserved set */
    uint32_t usable_sets;
diff --git a/src/freedreno/vulkan/tu_knl_drm_msm.cc b/src/freedreno/vulkan/tu_knl_drm_msm.cc
index 5388b32..74ef09d 100644
--- a/src/freedreno/vulkan/tu_knl_drm_msm.cc
+++ b/src/freedreno/vulkan/tu_knl_drm_msm.cc
@@ -158,6 +158,17 @@ tu_drm_get_ubwc_swizzle(const struct tu_physical_device *dev)
    return value;
 }
 
+static uint64_t
+tu_drm_get_uche_trap_base(const struct tu_physical_device *dev)
+{
+   uint64_t value;
+   int ret = tu_drm_get_param(dev->local_fd, MSM_PARAM_UCHE_TRAP_BASE, &value);
+   if (ret)
+      return 0x1fffffffff000ull;
+
+   return value;
+}
+
 static bool
 tu_drm_is_memory_type_supported(int fd, uint32_t flags)
 {
@@ -1051,6 +1062,8 @@ tu_knl_drm_msm_load(struct tu_instance *instance,
    device->ubwc_config.bank_swizzle_levels = tu_drm_get_ubwc_swizzle(device);
    device->ubwc_config.macrotile_mode = tu_drm_get_macrotile_mode(device);
 
+   device->uche_trap_base = tu_drm_get_uche_trap_base(device);
+
    device->syncobj_type = vk_drm_syncobj_get_type(fd);
    /* we don't support DRM_CAP_SYNCOBJ_TIMELINE, but drm-shim does */
    if (!(device->syncobj_type.features & VK_SYNC_FEATURE_TIMELINE))
diff --git a/src/freedreno/vulkan/tu_knl_drm_virtio.cc b/src/freedreno/vulkan/tu_knl_drm_virtio.cc
index c4630f3..efc02c4 100644
--- a/src/freedreno/vulkan/tu_knl_drm_virtio.cc
+++ b/src/freedreno/vulkan/tu_knl_drm_virtio.cc
@@ -286,6 +286,17 @@ tu_drm_get_ubwc_swizzle(struct vdrm_device *vdrm)
    return value;
 }
 
+static uint32_t
+tu_drm_get_uche_trap_base(struct vdrm_device *vdrm)
+{
+   uint64_t value;
+   int ret = tu_drm_get_param(vdrm, MSM_PARAM_UCHE_TRAP_BASE, &value);
+   if (ret)
+      return 0x1fffffffff000ull;
+
+   return value;
+}
+
 static int
 virtio_device_get_gpu_timestamp(struct tu_device *dev, uint64_t *ts)
 {
@@ -1143,6 +1154,7 @@ tu_knl_drm_virtio_load(struct tu_instance *instance,
    /* TODO add these to the caps struct */
    uint32_t bank_swizzle_levels = tu_drm_get_ubwc_swizzle(vdrm);
    enum fdl_macrotile_mode macrotile_mode = tu_drm_get_macrotile_mode(vdrm);
+   uint64_t uche_trap_base = tu_drm_get_uche_trap_base(vdrm);
 
    vdrm_device_close(vdrm);
 
@@ -1202,6 +1214,7 @@ tu_knl_drm_virtio_load(struct tu_instance *instance,
    device->ubwc_config.highest_bank_bit = caps.u.msm.highest_bank_bit;
    device->has_set_iova   = true;
    device->has_preemption = has_preemption;
+   device->uche_trap_base = uche_trap_base;
 
    device->ubwc_config.bank_swizzle_levels = bank_swizzle_levels;
    device->ubwc_config.macrotile_mode = macrotile_mode;
diff --git a/src/freedreno/vulkan/tu_knl_kgsl.cc b/src/freedreno/vulkan/tu_knl_kgsl.cc
index b6e17fd..30cf10a 100644
--- a/src/freedreno/vulkan/tu_knl_kgsl.cc
+++ b/src/freedreno/vulkan/tu_knl_kgsl.cc
@@ -1436,6 +1436,11 @@ tu_knl_kgsl_load(struct tu_instance *instance, int fd)
                      sizeof(ubwc_version)))
       goto fail;
 
+   if (get_kgsl_prop(fd, KGSL_PROP_UCHE_TRAP_BASE, &device->uche_trap_base,
+                     sizeof(device->uche_trap_base))) {
+      /* It is known to be hardcoded to */
+      device->uche_trap_base = 0x1fffffffff000ull;
+   }
 
    /* kgsl version check? */
 
diff --git a/src/gallium/drivers/freedreno/freedreno_screen.c b/src/gallium/drivers/freedreno/freedreno_screen.c
index 907da52..08eb17c 100644
--- a/src/gallium/drivers/freedreno/freedreno_screen.c
+++ b/src/gallium/drivers/freedreno/freedreno_screen.c
@@ -608,6 +608,8 @@ fd_screen_get_param(struct pipe_screen *pscreen, enum pipe_cap param)
       return 0;
    case PIPE_CAP_THROTTLE:
       return screen->driconf.enable_throttling;
+   case PIPE_CAP_SHADER_CLOCK:
+      return is_a6xx(screen);
    default:
       return u_pipe_screen_get_param_defaults(pscreen, param);
    }
@@ -1138,6 +1140,9 @@ fd_screen_create(int fd,
 
    screen->has_syncobj = fd_has_syncobj(screen->dev);
 
+   if (fd_pipe_get_param(screen->pipe, FD_UCHE_TRAP_BASE, &val))
+      screen->uche_trap_base = screen->gen >= 6 ? 0x1fffffffff000ull : 0ull;
+
    /* parse driconf configuration now for device specific overrides: */
    driParseConfigFiles(config->options, config->options_info, 0, "msm",
                        NULL, fd_dev_name(screen->dev_id), NULL, 0, NULL, 0);
diff --git a/src/gallium/drivers/freedreno/freedreno_screen.h b/src/gallium/drivers/freedreno/freedreno_screen.h
index bdd446b..a1ec670 100644
--- a/src/gallium/drivers/freedreno/freedreno_screen.h
+++ b/src/gallium/drivers/freedreno/freedreno_screen.h
@@ -67,6 +67,8 @@ struct fd_screen {
    uint64_t gmem_base;
    uint32_t gmemsize_bytes;
 
+   uint64_t uche_trap_base;
+
    const struct fd_dev_id *dev_id;
    uint8_t gen;      /* GPU (major) generation */
    uint32_t gpu_id;  /* 220, 305, etc */
diff --git a/src/gallium/drivers/freedreno/ir3/ir3_gallium.c b/src/gallium/drivers/freedreno/ir3/ir3_gallium.c
index 6eeac05..969ff69 100644
--- a/src/gallium/drivers/freedreno/ir3/ir3_gallium.c
+++ b/src/gallium/drivers/freedreno/ir3/ir3_gallium.c
@@ -559,6 +559,7 @@ ir3_screen_init(struct pipe_screen *pscreen)
       .bindless_fb_read_slot = IR3_BINDLESS_IMAGE_OFFSET +
                                IR3_BINDLESS_IMAGE_COUNT - 1 - screen->max_rts,
       .dual_color_blend_by_location = screen->driconf.dual_color_blend_by_location,
+      .uche_trap_base = screen->uche_trap_base,
    };
 
    if (screen->gen >= 6) {
